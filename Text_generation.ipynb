{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Reading the training file\n",
    "train_data = open('company_data_preprocessed.csv', 'r')\n",
    "lines = train_data.readlines()\n",
    "train_data.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\" \"\"Hoist Kredit AB is a Swedish financial services company. Hoist is active in nine European countries, and specializes in the acquisition and management of non-performing consumer loans. Hoist manages approximately 4 million receivables with a total aggregate face value of approximately EUR 9.5 billion and gross collections amounted to EUR 730 million in 2014. Hoist was previously listed on the Stockholm Stock Exchange but was de-listed in 2004. In 2003 the company divested its operations in non-performing consumer loans in Sweden but has since 2009 offered deposit accounts in Sweden, and now has a total deposit base of SEK 8 billion. In 2012 Hoist was one of the largest acquirers of non-performing consumer loans in Europe with an acquisition volume of approximately SEK 2 billion ,\"\" one significant acquisition being the acquisition of the UK debt-collection agency Robinson Way Ltd. On October 2013 Hoist listed a 10-year bond for SEK 350 million on Nasdaq OMX Stockholm.\"\"\"\"\"\",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,\"\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Let's check how the data looks like\n",
    "\n",
    "lines[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\" \"\"hoist kredit ab is a swedish financial services company. hoist is active in nine european countries, and specializes in the acquisition and management of non-performing consumer loans. hoist manages approximately 4 million receivables with a total aggregate face value of approximately eur 9.5 billion and gross collections amounted to eur 730 million in 2014. hoist was previously listed on the stockholm stock exchange but was de-listed in 2004. in 2003 the company divested its operations in non-performing consumer loans in sweden but has since 2009 offered deposit accounts in sweden, and now has a total deposit base of sek 8 billion. in 2012 hoist was one of the largest acquirers of non-performing consumer loans in europe with an acquisition volume of approximately sek 2 billion ,\"\" one significant acquisition being the acquisition of the uk debt-collection agency robinson way ltd. on october 2013 hoist listed a 10-year bond for sek 350 million on nasdaq omx stockholm.\"\"\"\"\"\",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,\"\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines = [word.lower().strip('\\s+') for word in lines]\n",
    "lines[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing punctuations\n",
    "import string\n",
    "def remove_punctuation(text):  \n",
    "    punct_remove = [punct for punct in str(text) if punct not in string.punctuation]\n",
    "    punct_remove = ''.join(punct_remove)\n",
    "    return punct_remove\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " hoist kredit ab is a swedish financial services company hoist is active in nine european countries and specializes in the acquisition and management of nonperforming consumer loans hoist manages approximately 4 million receivables with a total aggregate face value of approximately eur 95 billion and gross collections amounted to eur 730 million in 2014 hoist was previously listed on the stockholm stock exchange but was delisted in 2004 in 2003 the company divested its operations in nonperforming consumer loans in sweden but has since 2009 offered deposit accounts in sweden and now has a total deposit base of sek 8 billion in 2012 hoist was one of the largest acquirers of nonperforming consumer loans in europe with an acquisition volume of approximately sek 2 billion  one significant acquisition being the acquisition of the uk debtcollection agency robinson way ltd on october 2013 hoist listed a 10year bond for sek 350 million on nasdaq omx stockholm\n",
      "\n"
     ]
    }
   ],
   "source": [
    "text_list = []\n",
    "for i in range(0,len(lines)):\n",
    "    text_list.append(remove_punctuation(lines[i]))\n",
    "\n",
    "with open('company_file_preprocessed_small.txt', 'w') as f:\n",
    "    for item in text_list:\n",
    "        f.write(\"%s\" % item)\n",
    "\n",
    "print(text_list[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "text=(open(\"company_file_preprocessed_small.txt\").read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total chars:  38\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set(text)))\n",
    "print('total chars: ', len(chars))\n",
    "print(chars[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Characters:  6721204\n",
      "Total Vocab:  38\n"
     ]
    }
   ],
   "source": [
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))\n",
    "n_chars = len(text)\n",
    "n_vocab = len(chars)\n",
    "print(\"Total Characters: \", n_chars)\n",
    "print(\"Total Vocab: \", n_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "maxlen = 40\n",
    "step = 3\n",
    "sentences = []\n",
    "next_chars = []\n",
    "for i in range(0, len(text) - maxlen, step):\n",
    "    sentences.append(text[i: i + maxlen])\n",
    "    next_chars.append(text[i + maxlen])\n",
    "x = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)\n",
    "y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n",
    "for i, sentence in enumerate(sentences):\n",
    "    for t, char in enumerate(sentence):\n",
    "        x[i, t, char_indices[char]] = 1\n",
    "    y[i, char_indices[next_chars[i]]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.layers import LSTM\n",
    "from keras.optimizers import RMSprop\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(maxlen, len(chars))))\n",
    "model.add(Dense(len(chars)))\n",
    "model.add(Activation('softmax'))\n",
    "optimizer = RMSprop(lr=0.01)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import LambdaCallback\n",
    "import sys\n",
    "def sample(preds, temperature=1.0):\n",
    "    # helper function to sample an index from a probability array\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)\n",
    "def on_epoch_end(epoch, logs):\n",
    "    # Function invoked at end of each epoch. Prints generated text.\n",
    "    print()\n",
    "    print('----- Generating text after Epoch: %d' % epoch)\n",
    "\n",
    "    start_index = random.randint(0, len(text) - maxlen - 1)\n",
    "    for diversity in [0.2, 0.5, 1.0, 1.2]:\n",
    "        print('----- diversity:', diversity)\n",
    "\n",
    "        generated = ''\n",
    "        sentence = text[start_index: start_index + maxlen]\n",
    "        generated += sentence\n",
    "        print('----- Generating with seed: \"' + sentence + '\"')\n",
    "        sys.stdout.write(generated)\n",
    "\n",
    "        for i in range(100):\n",
    "            x_pred = np.zeros((1, maxlen, len(chars)))\n",
    "            for t, char in enumerate(sentence):\n",
    "                x_pred[0, t, char_indices[char]] = 1.\n",
    "\n",
    "            preds = model.predict(x_pred, verbose=0)[0]\n",
    "            next_index = sample(preds, diversity)\n",
    "            next_char = indices_char[next_index]\n",
    "\n",
    "            generated += next_char\n",
    "            sentence = sentence[1:] + next_char\n",
    "\n",
    "            sys.stdout.write(next_char)\n",
    "            sys.stdout.flush()\n",
    "        print()\n",
    "print_callback = LambdaCallback(on_epoch_end=on_epoch_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "filepath = \"weights.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='loss',\n",
    "                             verbose=1, save_best_only=True,\n",
    "                             mode='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ReduceLROnPlateau\n",
    "reduce_lr = ReduceLROnPlateau(monitor='loss', factor=0.2,\n",
    "                              patience=1, min_lr=0.001)\n",
    "callbacks = [print_callback, checkpoint, reduce_lr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "2240388/2240388 [==============================] - 2568s 1ms/step - loss: 2.7596\n",
      "\n",
      "----- Generating text after Epoch: 0\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"to aol video search\n",
      " beijing capital int\"\n",
      "to aol video search\n",
      " beijing capital intern the a comio a com"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shalu/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:6: RuntimeWarning: divide by zero encountered in log\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ions and an a buai of south commerse the compaind compan was a coal an a oolio \n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"to aol video search\n",
      " beijing capital int\"\n",
      "to aol video search\n",
      " beijing capital intern the a comio a sero coi the to a soai  of the lideratio company are a set a rong compai a fo the \n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"to aol video search\n",
      " beijing capital int\"\n",
      "to aol video search\n",
      " beijing capital intire botoi sbh i ioccgiemo and on ookh a industish for thou ioning a ndbagoperlis a a iowlio caindia \n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \"to aol video search\n",
      " beijing capital int\"\n",
      "to aol video search\n",
      " beijing capital intern ruso and o io 4 to r a roo wea avea enih progiation ond ode tuksh ly whio baiisticeu oo heldfoom\n",
      "\n",
      "Epoch 00001: loss improved from inf to 2.75965, saving model to weights.hdf5\n",
      "Epoch 2/5\n",
      "2240388/2240388 [==============================] - 2483s 1ms/step - loss: 4.6001\n",
      "\n",
      "----- Generating text after Epoch: 1\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"ia in 1997h   owned by malrite communica\"\n",
      "ia in 1997h   owned by malrite communicab1der in  thu toreus t 30  cth cogpe 1uator2e4ng wr0 poor\n",
      " men in fo t thbe  rithel toend   the core\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"ia in 1997h   owned by malrite communica\"\n",
      "ia in 1997h   owned by malrite communicaa99t int cogrmdbvz2 ve t di laqat cmsaan mrt lner 3nel3l   are kr0 s s an itpats in thershhd ai hioj\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"ia in 1997h   owned by malrite communica\"\n",
      "ia in 1997h   owned by malrite communicawfnlin w ocmikens ao9aorpo uas rr rb  outnmu iph tloncoosa umw al aren tos uolili pag arijan a ceasi\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \"ia in 1997h   owned by malrite communica\"\n",
      "ia in 1997h   owned by malrite communicapyonase pon ahatdi senie1orm i fllw o fling\n",
      "cp5at erar ae udarniraldic oinmsto t o \n",
      " anorgnfislsioo \n",
      "\n",
      "Epoch 00002: loss did not improve from 2.75965\n",
      "Epoch 3/5\n",
      "2240388/2240388 [==============================] - 2026s 904us/step - loss: 6.1402\n",
      "\n",
      "----- Generating text after Epoch: 2\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"west bengal it paid us144 billion  791 b\"\n",
      "west bengal it paid us144 billion  791 b an  arenit te  re con on con cthh ar  cernr in chonhhnh cv he pan ono ntpr  in cnen  thena  ine i3 \n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"west bengal it paid us144 billion  791 b\"\n",
      "west bengal it paid us144 billion  791 busent anen t aricsieneinjin idhont  orfm onpcee adx hist cir a  can o nite i1 ant  the aa tidhn  o t\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"west bengal it paid us144 billion  791 b\"\n",
      "west bengal it paid us144 billion  791 bes0c astl noon onrsn cau c ani ttre ldtdueis neo iratae l cidoelil u necsu thenrirddssisaitic2t oed \n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \"west bengal it paid us144 billion  791 b\"\n",
      "west bengal it paid us144 billion  791 b leaeaee ottea chore ner lannines we su hionxln e eawd tijnoteate ashn ejttiik ai uonulhn ion in toa\n",
      "\n",
      "Epoch 00003: loss did not improve from 2.75965\n",
      "Epoch 4/5\n",
      "2240388/2240388 [==============================] - 1696s 757us/step - loss: 5.6936\n",
      "\n",
      "----- Generating text after Epoch: 3\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"air force an improved allmetal derivativ\"\n",
      "air force an improved allmetal derivativ therxe ino  am  e and na and t cgin t the th a ond an met an an t chan the a ath sacond t an an a  \n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"air force an improved allmetal derivativ\"\n",
      "air force an improved allmetal derivativ thatenond  an t th ne  conen costaubt ia ou as on the h anoros  ch thein t aacten ptet esess e s e \n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"air force an improved allmetal derivativ\"\n",
      "air force an improved allmetal derivativop0anvneahd c tetd patie orrid dche0oes e hecq ireioiouloe anto hrhe st  tileto aneco aneds tleskiol\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \"air force an improved allmetal derivativ\"\n",
      "air force an improved allmetal derivativ tacari8 eleithlad  asnern t deo idruoreiacepeanqfirx isreutoaaenhetqe acueaca ceeh oan naateanssxto\n",
      "\n",
      "Epoch 00004: loss did not improve from 2.75965\n",
      "Epoch 5/5\n",
      "2054656/2240388 [==========================>...] - ETA: 4:59 - loss: 5.2002"
     ]
    }
   ],
   "source": [
    "model.fit(x, y, batch_size=128, epochs=5, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(length, diversity):\n",
    "    # Get random starting text\n",
    "    start_index = random.randint(0, len(text) - maxlen - 1)\n",
    "    generated = ''\n",
    "    sentence = text[start_index: start_index + maxlen]\n",
    "    generated += sentence\n",
    "    for i in range(length):\n",
    "            x_pred = np.zeros((1, maxlen, len(chars)))\n",
    "            for t, char in enumerate(sentence):\n",
    "                x_pred[0, t, char_indices[char]] = 1.\n",
    "\n",
    "            preds = model.predict(x_pred, verbose=0)[0]\n",
    "            next_index = sample(preds, diversity)\n",
    "            next_char = indices_char[next_index]\n",
    "\n",
    "            generated += next_char\n",
    "            sentence = sentence[1:] + next_char\n",
    "    return generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(generate_text(500, 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
